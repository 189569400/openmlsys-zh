## 总结

-   不同的模型部署场景下，通常对于模型大小、运行时内存占用、推理时延和推理功耗等指标有限制。

-   针对模型大小指标，通常在离线阶段通过模型压缩技术来优化，比如量化技术、剪枝技术、知识蒸馏技术等，除此之外，一部分模型优化技术，比如融合技术([1.2.2](#sec:ch09/ch09-kernel-fusion){reference-type="ref"
    reference="sec:ch09/ch09-kernel-fusion"})等，也有助于模型轻量化，不过其效果比较微弱。

-   总结未完。
